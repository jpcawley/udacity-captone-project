{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# People Names and Storms, Any Correlation?\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "Build an ETL pipeline that pulls publicly available state, baby name, and storm datasets into an S3 bucket, processes it with Spark, and writes it back to S3 as a set of dimension and fact tables.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:14:16.366860Z",
     "iopub.status.busy": "2022-10-17T13:14:16.366419Z",
     "iopub.status.idle": "2022-10-17T13:15:08.773203Z",
     "shell.execute_reply": "2022-10-17T13:15:08.771597Z",
     "shell.execute_reply.started": "2022-10-17T13:14:16.366760Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bfd552ef2745d49bd63f820a84eb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1666012200556_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-35-1.ec2.internal:20888/proxy/application_1666012200556_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-41-75.ec2.internal:8042/node/containerlogs/container_1666012200556_0001_01_000001/livy\">Link</a></td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==0.23.2\n",
      "  Downloading pandas-0.23.2-cp36-cp36m-manylinux1_x86_64.whl (8.9 MB)\n",
      "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/site-packages (from pandas==0.23.2) (2019.3)\n",
      "Collecting python-dateutil>=2.5.0\n",
      "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib64/python3.6/site-packages (from pandas==0.23.2) (1.14.5)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas==0.23.2) (1.12.0)\n",
      "Installing collected packages: python-dateutil, pandas\n",
      "Successfully installed pandas-0.23.2 python-dateutil-2.8.2\n",
      "\n",
      "Collecting geopy==2.2.0\n",
      "  Downloading geopy-2.2.0-py3-none-any.whl (118 kB)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Downloading geographiclib-1.52-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-1.52 geopy-2.2.0\n",
      "\n",
      "Collecting certifi==2019.11.28\n",
      "  Downloading certifi-2019.11.28-py2.py3-none-any.whl (156 kB)\n",
      "Installing collected packages: certifi\n",
      "Successfully installed certifi-2019.11.28"
     ]
    }
   ],
   "source": [
    "sc.install_pypi_package(\"pandas==0.23.2\")\n",
    "sc.install_pypi_package(\"geopy==2.2.0\")\n",
    "sc.install_pypi_package(\"certifi==2019.11.28\")\n",
    "sc.install_pypi_package(\"xlrd==0.9.0\")\n",
    "sc._jsc.hadoopConfiguration().set(\"mapreduce.fileoutputcommitter.algorithm.version\", \"2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:08.775686Z",
     "iopub.status.busy": "2022-10-17T13:15:08.775361Z",
     "iopub.status.idle": "2022-10-17T13:15:09.843352Z",
     "shell.execute_reply": "2022-10-17T13:15:09.842200Z",
     "shell.execute_reply.started": "2022-10-17T13:15:08.775658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89f68fdc7bf41edbbd0a3fd8dfbb2bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import configparser\n",
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import *\n",
    "from functools import reduce\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyspark.sql.types import StructType as R, StructField as Fld\n",
    "\n",
    "bucket = 's3a://jccapstonedata/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def get_S3_bucket():\n",
    "    ''' Retrieve S3 bucket path. '''\n",
    "\n",
    "    config = configparser.ConfigParser()\n",
    "    config.read('dl.cfg')\n",
    "\n",
    "    BUCKET = config.get('S3', 'BUCKET')\n",
    "\n",
    "    return BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    ''' Function that creates or retrieves an existing SparkSession. '''\n",
    "\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "* Extract data on various storms and join it with SS name and state datasets. The storm data undergoes some initial transformations with pandas to make it readily availble for further processing in PySpark.\n",
    "* The raw datasets are uploaded to S3, explored in greater detail with Apache Spark and Pandas, and then reuploaded to S3 as a set of dimension and fact tables. \n",
    "* The end goal is to provide enough information for an analyst to be able to answer questions regarding naming patterns between people and storms, popular names by state over a range of years, and general information regarding storms through the same range of years. \n",
    "\n",
    "#### Describe and Gather Data \n",
    "1. HURDAT2: Comes from the Hurricane Research Division's (HRD) Atlantic Oceanographic and Meteorological Laboratory (AOML) and provides storm name, status, maintained wind speed, location(s) over a storm's course, and other information (~55,000 rows)\n",
    "2. Name: Comes from the Social Security Administration (SSA) and provides birth name, birth year, birth state, sex, and name popularity (~6.3 million rows)\n",
    "3. State: Come from Kaggle and provides state name, code, region, and division (51 rows)\n",
    "4. Saffir-Simpson Wind Scale: Comes from the National Hurrican Center and provides a hurricane's categorization based on maintained wind speeds (5 rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create Saffir-Simpson Hurricane Wind Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:09.846512Z",
     "iopub.status.busy": "2022-10-17T13:15:09.845877Z",
     "iopub.status.idle": "2022-10-17T13:15:10.422990Z",
     "shell.execute_reply": "2022-10-17T13:15:10.349912Z",
     "shell.execute_reply.started": "2022-10-17T13:15:09.846466Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6625014873f4eb0844071b271dfdb07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [{'category': '1', 'min_sustained_wind(kt)': 64, 'max_sustained_wind(kt)': 82, 'brief_damage_description': 'Power outages that could last a few to several days.'}, \n",
    "            {'category': '2', 'min_sustained_wind(kt)': 83, 'max_sustained_wind(kt)': 95, 'brief_damage_description': 'Near-total power loss is expected with outages that could last from several days to weeks.'},\n",
    "            {'category': '3-MAJOR', 'min_sustained_wind(kt)': 96, 'max_sustained_wind(kt)': 112, 'brief_damage_description': 'Electricity and water will be unavailable for several days to weeks after the storm passes.'},\n",
    "            {'category': '4-MAJOR', 'min_sustained_wind(kt)': 113, 'max_sustained_wind(kt)': 136, 'brief_damage_description': 'Catastrophic damage will occur; most of the area will be uninhabitable for weeks or months.'},\n",
    "            {'category': '5-MAJOR', 'min_sustained_wind(kt)': 137, 'max_sustained_wind(kt)': 1000000, 'brief_damage_description': 'Catastrophic damage will occur; most of the area will be uninhabitable for weeks or months.'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:10.425583Z",
     "iopub.status.busy": "2022-10-17T13:15:10.425130Z",
     "iopub.status.idle": "2022-10-17T13:15:10.677403Z",
     "shell.execute_reply": "2022-10-17T13:15:10.676552Z",
     "shell.execute_reply.started": "2022-10-17T13:15:10.425516Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9301919966745439f98f3e665a67290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd_wind_scale = pd.DataFrame(data)\n",
    "\n",
    "wind_scale = pd_wind_scale[['category', 'min_sustained_wind(kt)', 'max_sustained_wind(kt)', 'brief_damage_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:10.723028Z",
     "iopub.status.busy": "2022-10-17T13:15:10.678999Z",
     "iopub.status.idle": "2022-10-17T13:15:12.225712Z",
     "shell.execute_reply": "2022-10-17T13:15:12.224410Z",
     "shell.execute_reply.started": "2022-10-17T13:15:10.722960Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08e2f7d4aab3405ba4cb495fe57c65b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/session.py:346: UserWarning: inferring schema from dict is deprecated,please use pyspark.sql.Row instead"
     ]
    }
   ],
   "source": [
    "spark_wind_scale = spark.createDataFrame(data)\n",
    "\n",
    "saffir_simpson_hurricane_wind_scale = spark_wind_scale.select('category', 'min_sustained_wind(kt)', 'max_sustained_wind(kt)', \n",
    "                                                             'brief_damage_description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saffir_simpson_hurricane_wind_scale.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read Storm Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:12.230503Z",
     "iopub.status.busy": "2022-10-17T13:15:12.229869Z",
     "iopub.status.idle": "2022-10-17T13:15:20.011068Z",
     "shell.execute_reply": "2022-10-17T13:15:20.009451Z",
     "shell.execute_reply.started": "2022-10-17T13:15:12.230459Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "388c662f67d94c599a014382836dd530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------------+-------+----+------+-------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|_c0|       0|                  1|      2|   3|     4|      5|   6|    7|    8|    9|   10|   11|   12|   13|   14|   15|   16|   17|   18|   19|   20|\n",
      "+---+--------+-------------------+-------+----+------+-------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "|  0|AL011851|            UNNAMED|     14|null|  null|   null|null| null| null| null| null| null| null| null| null| null| null| null| null| null| null|\n",
      "|  1|18510625|               0000|       |  HU| 28.0N|  94.8W|  80| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999|\n",
      "|  2|18510625|               0600|       |  HU| 28.0N|  95.4W|  80| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999|\n",
      "|  3|18510625|               1200|       |  HU| 28.0N|  96.0W|  80| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999|\n",
      "|  4|18510625|               1800|       |  HU| 28.1N|  96.5W|  80| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999| -999|\n",
      "+---+--------+-------------------+-------+----+------+-------+----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+-----+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "raw_storm_data = spark.read.csv(os.path.join(bucket, '*', 'raw_storm_data.csv'), header=True)\n",
    "raw_storm_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read Names by State Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:20.013976Z",
     "iopub.status.busy": "2022-10-17T13:15:20.013196Z",
     "iopub.status.idle": "2022-10-17T13:15:21.521071Z",
     "shell.execute_reply": "2022-10-17T13:15:21.519974Z",
     "shell.execute_reply.started": "2022-10-17T13:15:20.013928Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead852f4e26d4bb4b472b6125eec19ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               value|\n",
      "+--------------------+\n",
      "|  CA,F,1910,Mary,295|\n",
      "| CA,F,1910,Helen,239|\n",
      "|CA,F,1910,Dorothy...|\n",
      "|CA,F,1910,Margare...|\n",
      "|CA,F,1910,Frances...|\n",
      "+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "raw_name_data = spark.read.text(os.path.join(bucket, '*', '*', '*.TXT'))\n",
    "raw_name_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Read State Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:21.527707Z",
     "iopub.status.busy": "2022-10-17T13:15:21.527303Z",
     "iopub.status.idle": "2022-10-17T13:15:22.937157Z",
     "shell.execute_reply": "2022-10-17T13:15:22.931750Z",
     "shell.execute_reply.started": "2022-10-17T13:15:21.527674Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1bd1589eb8e4c178a8e2e41c4361abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+----------+----------+\n",
      "|          Division|Region|     State|State Code|\n",
      "+------------------+------+----------+----------+\n",
      "|           Pacific|  West|    Alaska|        AK|\n",
      "|East South Central| South|   Alabama|        AL|\n",
      "|West South Central| South|  Arkansas|        AR|\n",
      "|          Mountain|  West|   Arizona|        AZ|\n",
      "|           Pacific|  West|California|        CA|\n",
      "+------------------+------+----------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "raw_state_data = spark.read.json(os.path.join(bucket, '*', 'states.json'))\n",
    "raw_state_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:11.002438Z",
     "iopub.status.busy": "2022-10-17T13:16:11.002098Z",
     "iopub.status.idle": "2022-10-17T13:16:11.267287Z",
     "shell.execute_reply": "2022-10-17T13:16:11.265107Z",
     "shell.execute_reply.started": "2022-10-17T13:16:11.002407Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4bb51633eb481bae59f2f965fad98d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def missing_values(df):\n",
    "    num_nulls = df.select([F.count(F.when(F.isnan(c) | F.col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
    "    return num_nulls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:11.806109Z",
     "iopub.status.busy": "2022-10-17T13:16:11.805779Z",
     "iopub.status.idle": "2022-10-17T13:16:12.142243Z",
     "shell.execute_reply": "2022-10-17T13:16:12.140698Z",
     "shell.execute_reply.started": "2022-10-17T13:16:11.806079Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60a08abfea04b59a522f3a8a96bc0af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def duplicates(df):\n",
    "    num_dups = df.groupBy(df.columns).count().filter(\"count > 1\").count()\n",
    "    return num_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "tags": []
   },
   "source": [
    "##### Check for missing values and duplicates in name data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:12.797233Z",
     "iopub.status.busy": "2022-10-17T13:16:12.796880Z",
     "iopub.status.idle": "2022-10-17T13:16:18.475637Z",
     "shell.execute_reply": "2022-10-17T13:16:18.474505Z",
     "shell.execute_reply.started": "2022-10-17T13:16:12.797202Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca3f998ab4f48d3854e0951190c3046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in baby name dataset\n",
      "+-----+\n",
      "|value|\n",
      "+-----+\n",
      "|    0|\n",
      "+-----+"
     ]
    }
   ],
   "source": [
    "print('Missing values in baby name dataset')\n",
    "missing_values(raw_name_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:18.479297Z",
     "iopub.status.busy": "2022-10-17T13:16:18.478319Z",
     "iopub.status.idle": "2022-10-17T13:16:22.234915Z",
     "shell.execute_reply": "2022-10-17T13:16:22.233821Z",
     "shell.execute_reply.started": "2022-10-17T13:16:18.479252Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68476bf34d564028aac6f5e4483645c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates in baby name dataset: 0"
     ]
    }
   ],
   "source": [
    "print('Total duplicates in baby name dataset:', duplicates(raw_name_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check for missing values and duplicates in state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:22.237537Z",
     "iopub.status.busy": "2022-10-17T13:16:22.237065Z",
     "iopub.status.idle": "2022-10-17T13:16:23.241973Z",
     "shell.execute_reply": "2022-10-17T13:16:23.240485Z",
     "shell.execute_reply.started": "2022-10-17T13:16:22.237493Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5afd45c9f554f28b645291dee7b6ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in states dataset\n",
      "+--------+------+-----+----------+\n",
      "|Division|Region|State|State Code|\n",
      "+--------+------+-----+----------+\n",
      "|       0|     0|    0|         0|\n",
      "+--------+------+-----+----------+"
     ]
    }
   ],
   "source": [
    "print('Missing values in states dataset')\n",
    "missing_values(raw_state_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:23.244256Z",
     "iopub.status.busy": "2022-10-17T13:16:23.243908Z",
     "iopub.status.idle": "2022-10-17T13:16:24.333453Z",
     "shell.execute_reply": "2022-10-17T13:16:24.332094Z",
     "shell.execute_reply.started": "2022-10-17T13:16:23.244214Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f697e888d9c48479070ef9aa541743b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates in states dataset: 0"
     ]
    }
   ],
   "source": [
    "print('Total duplicates in states dataset:', duplicates(raw_state_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "##### Check for missing values and duplicates in raw storm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:16:24.336661Z",
     "iopub.status.busy": "2022-10-17T13:16:24.336040Z",
     "iopub.status.idle": "2022-10-17T13:16:26.647244Z",
     "shell.execute_reply": "2022-10-17T13:16:26.642998Z",
     "shell.execute_reply.started": "2022-10-17T13:16:24.336617Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adea479cb9d249ca8a460aafd7095a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in storm dataset\n",
      "+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|_c0|  0|  1|  2|   3|   4|   5|   6|   7|   8|   9|  10|  11|  12|  13|  14|  15|  16|  17|  18|  19|  20|\n",
      "+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|  0|  0|  0|  0|1933|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|1936|\n",
      "+---+---+---+---+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+"
     ]
    }
   ],
   "source": [
    "print('Missing values in storm dataset')\n",
    "missing_values(raw_storm_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:15:36.676286Z",
     "iopub.status.busy": "2022-10-17T13:15:36.675724Z",
     "iopub.status.idle": "2022-10-17T13:15:39.728286Z",
     "shell.execute_reply": "2022-10-17T13:15:39.722969Z",
     "shell.execute_reply.started": "2022-10-17T13:15:36.676244Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3df99dd28b94eae9a7571a01f43032c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total duplicates in storm dataset: 0"
     ]
    }
   ],
   "source": [
    "print('Total duplicates in storm dataset:', duplicates(raw_storm_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Cleaning Steps\n",
    "Very little clean up is necessary. A deeper dive shows the missing values in the storm data set come from the header rows not having the same number of columns as the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:27:24.421421Z",
     "iopub.status.busy": "2022-10-17T13:27:24.421067Z",
     "iopub.status.idle": "2022-10-17T13:27:32.168495Z",
     "shell.execute_reply": "2022-10-17T13:27:32.162324Z",
     "shell.execute_reply.started": "2022-10-17T13:27:24.421389Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4c7620d85141269de759c3e6ae6f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------------------+-------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|_c0|       0|                  1|      2|   3|   4|   5|   6|   7|   8|   9|  10|  11|  12|  13|  14|  15|  16|  17|  18|  19|  20|\n",
      "+---+--------+-------------------+-------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "|  0|AL011851|            UNNAMED|     14|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "| 15|AL021851|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "| 17|AL031851|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "| 19|AL041851|            UNNAMED|     49|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "| 69|AL051851|            UNNAMED|     16|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "| 86|AL061851|            UNNAMED|     17|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|104|AL011852|            UNNAMED|     45|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|150|AL021852|            UNNAMED|      8|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|159|AL031852|            UNNAMED|     20|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|180|AL041852|            UNNAMED|     36|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|217|AL051852|            UNNAMED|     25|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|243|AL011853|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|245|AL021853|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|247|AL031853|            UNNAMED|     48|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|296|AL041853|            UNNAMED|     12|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|309|AL051853|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|311|AL061853|            UNNAMED|     22|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|334|AL071853|            UNNAMED|      1|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|336|AL081853|            UNNAMED|     14|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "|351|AL011854|            UNNAMED|     11|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|null|\n",
      "+---+--------+-------------------+-------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "raw_storm_data.filter(raw_storm_data['3'].isNull()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Map out the conceptual data model and explain why you chose that model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "![Schema](Capstone_Schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "At a high level, the transformations are done in both Pandas and Spark as Spark proved to perform poorly in certain cases. <br> As a data engineer I need to,\n",
    "1. Combine storm data row-wise and remove unnecessary columns\n",
    "* Make separate header dataframe and statistics dataframe and join them to create unique rows for storm data\n",
    "2. Filter out unnamed storms for storm and baby name analysis\n",
    "3. Breakdown storm id to get years for storm and baby name analysis\n",
    "4. Create a wind scale table to give storms typed as hurricanes a category for further analysis\n",
    "5. Combine storm and name data on name to analyze potential trends"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Baby Names by State Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:27:53.587442Z",
     "iopub.status.busy": "2022-10-17T13:27:53.586969Z",
     "iopub.status.idle": "2022-10-17T13:27:54.586264Z",
     "shell.execute_reply": "2022-10-17T13:27:54.585153Z",
     "shell.execute_reply.started": "2022-10-17T13:27:53.587409Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd2b677f6ce4a1fa31d18edaeff6f02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "split_col = F.split(raw_name_data.value, ',')\n",
    "names_by_state = raw_name_data.withColumn('state_code', split_col.getItem(0)) \\\n",
    ".withColumn('sex', split_col.getItem(1)) \\\n",
    ".withColumn('birth_year', split_col.getItem(2)) \\\n",
    ".withColumn('birth_name', split_col.getItem(3)) \\\n",
    ".withColumn('count', split_col.getItem(4)) \\\n",
    ".drop(raw_name_data.value)\n",
    "\n",
    "names_by_state = names_by_state.orderBy(['birth_year', 'state_code', 'birth_name']) \\\n",
    ".withColumn('name_id', F.row_number().over(Window.partitionBy().orderBy('birth_year', 'state_code', 'birth_name'))) \\\n",
    ".withColumn('decade', (F.floor(F.col('birth_year')/10)*10).cast('int')) \\\n",
    ".withColumn('birth_name', F.upper(F.col('birth_name')))\n",
    "\n",
    "baby_names_by_state = names_by_state.select('name_id', 'birth_name', 'birth_year', 'state_code', 'sex', 'count', 'decade')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "baby_names_by_state.write.partitionBy('state_code', 'birth_year').mode(\n",
    "        'overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### States table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:27:55.914693Z",
     "iopub.status.busy": "2022-10-17T13:27:55.913960Z",
     "iopub.status.idle": "2022-10-17T13:27:56.225031Z",
     "shell.execute_reply": "2022-10-17T13:27:56.223848Z",
     "shell.execute_reply.started": "2022-10-17T13:27:55.914253Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a363be7d51b4627830b71d09e600e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_data = raw_state_data.withColumnRenamed('State', 'state') \\\n",
    ".withColumnRenamed('State Code', 'state_code') \\\n",
    ".withColumnRenamed('Region', 'region') \\\n",
    ".withColumnRenamed('Division', 'division') \\\n",
    ".withColumn('state_id', F.row_number().over(Window.partitionBy().orderBy('state', 'state_code')))\n",
    "\n",
    "state_data = state_data.select('state_id', 'state_code', 'state', 'region', 'division')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "state_data.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Atlantic Storms Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Atlantic storms header table (helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:28:20.670365Z",
     "iopub.status.busy": "2022-10-17T13:28:20.669928Z",
     "iopub.status.idle": "2022-10-17T13:28:21.186991Z",
     "shell.execute_reply": "2022-10-17T13:28:21.183181Z",
     "shell.execute_reply.started": "2022-10-17T13:28:20.670330Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac700180ea94972b8689f59f1a91a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "identified_storms = raw_storm_data.filter(raw_storm_data['0'].contains('AL')).withColumnRenamed('0', 'storm_id') \\\n",
    ".withColumnRenamed('1', 'storm_name').withColumnRenamed('2', 'entries') \\\n",
    ".drop('3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20')\n",
    "\n",
    "atlantic_storms_by_year = identified_storms.withColumn('storm_id', F.trim(identified_storms.storm_id)) \\\n",
    ".withColumn('storm_name', F.trim(F.upper(F.col('storm_name')))) \\\n",
    ".withColumn('entries', F.trim(identified_storms.entries).cast(IntegerType())) \\\n",
    ".withColumn('basin', F.substring(F.col('storm_id'), 1, 2)) \\\n",
    ".withColumn('atcf_cyclone_num', F.substring(F.col('storm_id'), 3, 2).cast(IntegerType())) \\\n",
    ".withColumn('storm_year', F.substring(F.col('storm_id'), 5, 8).cast(IntegerType())) \\\n",
    ".withColumn('header_id', identified_storms._c0.cast(IntegerType())) \\\n",
    ".drop('_c0') \\\n",
    ".dropDuplicates()\n",
    "\n",
    "atlantic_storms_header = atlantic_storms_by_year.withColumn('header_id', atlantic_storms_by_year['header_id'].cast(IntegerType())).orderBy(F.asc('header_id')) \\\n",
    ".select('header_id', 'storm_id', 'storm_name', 'entries', 'basin', 'atcf_cyclone_num', 'storm_year')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:28:24.345116Z",
     "iopub.status.busy": "2022-10-17T13:28:24.344766Z",
     "iopub.status.idle": "2022-10-17T13:28:28.260207Z",
     "shell.execute_reply": "2022-10-17T13:28:28.258725Z",
     "shell.execute_reply.started": "2022-10-17T13:28:24.345084Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d8719636ce474a88d4d78f3e130340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+----------+-------+-----+----------------+----------+\n",
      "|header_id|storm_id|storm_name|entries|basin|atcf_cyclone_num|storm_year|\n",
      "+---------+--------+----------+-------+-----+----------------+----------+\n",
      "|        0|AL011851|   UNNAMED|     14|   AL|               1|      1851|\n",
      "|       15|AL021851|   UNNAMED|      1|   AL|               2|      1851|\n",
      "|       17|AL031851|   UNNAMED|      1|   AL|               3|      1851|\n",
      "|       19|AL041851|   UNNAMED|     49|   AL|               4|      1851|\n",
      "|       69|AL051851|   UNNAMED|     16|   AL|               5|      1851|\n",
      "+---------+--------+----------+-------+-----+----------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "atlantic_storms_header.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Atlantic storms stats table (helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:31:53.851069Z",
     "iopub.status.busy": "2022-10-17T13:31:53.850580Z",
     "iopub.status.idle": "2022-10-17T13:32:03.579268Z",
     "shell.execute_reply": "2022-10-17T13:32:03.576361Z",
     "shell.execute_reply.started": "2022-10-17T13:31:53.851035Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "086ad03ff1554a6183b394394f0f6820",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spark_storm_stats = raw_storm_data.filter(~raw_storm_data['0'].contains('AL')) \\\n",
    ".withColumnRenamed('0', 'date') \\\n",
    ".withColumnRenamed('1', 'time') \\\n",
    ".withColumnRenamed('2', 'record_identifier') \\\n",
    ".withColumnRenamed('3', 'storm_status') \\\n",
    ".withColumnRenamed('4', 'latitude') \\\n",
    ".withColumnRenamed('5', 'longitude') \\\n",
    ".withColumnRenamed('6', 'max_sustained_wind(kt)')\\\n",
    ".withColumnRenamed('7', 'min_pressure(mbar)') \\\n",
    ".drop('8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20')\n",
    "\n",
    "spark_storm_stats = spark_storm_stats.withColumn('storm_date', F.trim(spark_storm_stats.date)) \\\n",
    ".withColumn('storm_time', F.trim(spark_storm_stats.time)) \\\n",
    ".withColumn('record_identifier', F.trim(spark_storm_stats.record_identifier)) \\\n",
    ".withColumn('storm_status', F.trim(spark_storm_stats.storm_status)) \\\n",
    ".withColumn('max_sustained_wind(kt)', F.trim(spark_storm_stats['max_sustained_wind(kt)']).cast(IntegerType()))\\\n",
    ".withColumn('min_pressure(mbar)', F.trim(spark_storm_stats['min_pressure(mbar)']).cast(IntegerType())) \\\n",
    ".withColumn('stat_id', spark_storm_stats._c0.cast(IntegerType()))\n",
    "\n",
    "# extract year, month, and day from date column\n",
    "spark_storm_stats = spark_storm_stats.withColumn('storm_date', F.to_date(F.col('date'),'yyyyMMdd') )\n",
    "spark_storm_stats = spark_storm_stats.withColumn('storm_year', F.year(spark_storm_stats.storm_date).cast(IntegerType())) \\\n",
    ".withColumn('storm_month', F.month(spark_storm_stats.storm_date).cast(IntegerType())) \\\n",
    ".withColumn('storm_day', F.dayofmonth(spark_storm_stats.storm_date).cast(IntegerType())) \n",
    "\n",
    "spark_storm_stats = spark_storm_stats.select('stat_id', 'storm_date', 'storm_year', 'storm_month', 'storm_day', 'storm_time', 'record_identifier', \n",
    "                           'storm_status', 'latitude', 'longitude', 'max_sustained_wind(kt)', 'min_pressure(mbar)')\n",
    "\n",
    "atlantic_storm_stats = spark_storm_stats.toPandas()\n",
    "\n",
    "# doesn't look good in spark\n",
    "# atlantic_storm_stats['storm_time'] = pd.to_datetime(\n",
    "#         atlantic_storm_stats['storm_time'].str.strip(), format='%H%M').dt.time\n",
    "\n",
    "# tranform storm_status and record_identifier in atlantic_storms_stats\n",
    "atlantic_storm_stats.storm_status = atlantic_storm_stats.storm_status.str.strip() \\\n",
    ".map({'HU': 'hurricane', 'TS': 'tropical storm', 'EX': 'extratropical cyclone',\n",
    "     'TD': 'tropical depression', 'LO': 'low pressure system', 'DB': 'disturbance', \n",
    "      'SD': 'subtropical depression', 'SS': 'subtropical storm', 'WV': 'tropical wave'})\n",
    "\n",
    "atlantic_storm_stats.record_identifier = atlantic_storm_stats.record_identifier.str.strip()  \\\n",
    ".map({'': '', 'L': 'landfall', 'R': 'intensity details with rapid changes',\n",
    "      'I': 'pressure and wind intensity peak', 'P': 'min central pressure',\n",
    "      'T': 'clarify track detail', 'W': 'max sustained wind speed',\n",
    "      'C': 'approach to coast, no landfall', 'S': 'status change in system',\n",
    "      'G': 'genesis of the system'})\n",
    "\n",
    "# transform lat and long\n",
    "lat_north = pd.to_numeric(atlantic_storm_stats['latitude'].str[:-1])\n",
    "lat_south = pd.to_numeric(atlantic_storm_stats['latitude'].str[:-1])*-1\n",
    "long_east = pd.to_numeric(atlantic_storm_stats['longitude'].str[:-1])\n",
    "long_west = pd.to_numeric(atlantic_storm_stats['longitude'].str[:-1])*-1\n",
    "\n",
    "atlantic_storm_stats['latitude'] = np.where(\n",
    "    atlantic_storm_stats['latitude'].str[-1:] == 'N', lat_north, lat_south)\n",
    "atlantic_storm_stats['longitude'] = np.where(\n",
    "    atlantic_storm_stats['longitude'].str[-1:] == 'E', long_east, long_west)\n",
    "\n",
    "# get hurricane category by sustained_wind(kt)\n",
    "\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'] < wind_scale['min_sustained_wind(kt)'][0]), atlantic_storm_stats['storm_status'], 'uncategorized')\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'].between(wind_scale['min_sustained_wind(kt)'][0], wind_scale['max_sustained_wind(kt)'][0]+1)), wind_scale['category'][0], atlantic_storm_stats['storm_category'])\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'].between(wind_scale['min_sustained_wind(kt)'][1], wind_scale['max_sustained_wind(kt)'][1]+1)), wind_scale['category'][1], atlantic_storm_stats['storm_category'])\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'].between(wind_scale['min_sustained_wind(kt)'][2], wind_scale['max_sustained_wind(kt)'][2]+1)), wind_scale['category'][2], atlantic_storm_stats['storm_category'])\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'].between(wind_scale['min_sustained_wind(kt)'][3], wind_scale['max_sustained_wind(kt)'][3]+1)), wind_scale['category'][3], atlantic_storm_stats['storm_category'])\n",
    "atlantic_storm_stats['storm_category'] = np.where((atlantic_storm_stats['max_sustained_wind(kt)'] >= wind_scale['min_sustained_wind(kt)'][4]), wind_scale['category'][4], atlantic_storm_stats['storm_category'])\n",
    "\n",
    "pd_storm_stats = atlantic_storm_stats[['stat_id', 'storm_date', 'storm_year', 'storm_month', 'storm_day', 'storm_time', \n",
    "      'record_identifier', 'storm_status', 'storm_category', 'latitude', 'longitude', 'max_sustained_wind(kt)', 'min_pressure(mbar)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Define some schemas for storm data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:32:03.583116Z",
     "iopub.status.busy": "2022-10-17T13:32:03.582731Z",
     "iopub.status.idle": "2022-10-17T13:32:03.859753Z",
     "shell.execute_reply": "2022-10-17T13:32:03.858669Z",
     "shell.execute_reply.started": "2022-10-17T13:32:03.583072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03cb9002882467d9a4d99bbbe7dba3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType as R, StructField as Fld\n",
    "\n",
    "storm_stats_schema = StructType([\n",
    "    StructField('index', StringType()),\n",
    "    StructField('storm_date', DateType()),\n",
    "    StructField('storm_year', IntegerType()),\n",
    "    StructField('storm_month', IntegerType()),\n",
    "    StructField('storm_day', IntegerType()),\n",
    "    StructField('storm_time', StringType()),\n",
    "    StructField('record_identifier', StringType()),\n",
    "    StructField('storm_status', StringType()),\n",
    "    StructField('category', StringType()),\n",
    "    StructField('latitude', DoubleType()),\n",
    "    StructField('longitude', DoubleType()),\n",
    "    StructField('max_sustained_wind(kt)', IntegerType()),\n",
    "    StructField('min_pressure(mbar)', IntegerType())\n",
    "])\n",
    "\n",
    "storm_schema = R([\n",
    "    Fld('storm_id', StringType()),\n",
    "    Fld('basin', StringType()),\n",
    "    Fld('atcf_cyclone_num', IntegerType()),\n",
    "    Fld('storm_name', StringType()),\n",
    "    Fld('storm_date', DateType()),\n",
    "    Fld('storm_year', IntegerType()),\n",
    "    Fld('storm_month', IntegerType()),\n",
    "    Fld('storm_day', IntegerType()),\n",
    "    Fld('storm_time', StringType()),\n",
    "    Fld('record_identifier', StringType()),\n",
    "    Fld('storm_status', StringType()),\n",
    "    Fld('storm_category', StringType()),\n",
    "    Fld('latitude', DoubleType()),\n",
    "    Fld('longitude', DoubleType()),\n",
    "    Fld('max_sustained_wind(kt)', IntegerType()),\n",
    "    Fld('min_pressure(mbar)', IntegerType())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:32:04.262117Z",
     "iopub.status.busy": "2022-10-17T13:32:04.260504Z",
     "iopub.status.idle": "2022-10-17T13:32:05.856578Z",
     "shell.execute_reply": "2022-10-17T13:32:05.854670Z",
     "shell.execute_reply.started": "2022-10-17T13:32:04.262072Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1784ec73282648deb9d5740b5a0b4125",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atlantic_storm_stats = spark.createDataFrame(pd_storm_stats, storm_stats_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "atlantic_storm_stats.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Atlantic Storms Table (PANDAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:32:07.855254Z",
     "iopub.status.busy": "2022-10-17T13:32:07.854469Z",
     "iopub.status.idle": "2022-10-17T13:32:17.720473Z",
     "shell.execute_reply": "2022-10-17T13:32:17.719383Z",
     "shell.execute_reply.started": "2022-10-17T13:32:07.855200Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b865dd446f3d46b494e2a61636edf343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "storms_by_year = atlantic_storms_header.toPandas()\n",
    "\n",
    "storm_ids = list(storms_by_year.storm_id)\n",
    "names = list(storms_by_year.storm_name)\n",
    "basins = list(storms_by_year.basin)\n",
    "cyclone_nums = list(storms_by_year.atcf_cyclone_num)\n",
    "entries = storms_by_year.entries.apply(lambda x: int(x)).tolist()\n",
    "\n",
    "cols = ['storm_id', 'storm_name', 'basin', 'atcf_cyclone_num', 'storm_date', 'storm_year', 'storm_time', 'record_identifier',\n",
    "    'storm_status', 'storm_category', 'latitude', 'longitude', 'max_sustained_wind(kt)', 'min_pressure(mbar)']\n",
    "\n",
    "for i, nrows, nxt in zip(range(len(storms_by_year['header_id'])), entries, storms_by_year['header_id']):\n",
    "    temp_df = pd.DataFrame(pd_storm_stats.loc[(pd_storm_stats['stat_id'] >= nxt) & (pd_storm_stats['stat_id'] <= (nxt + nrows))])\n",
    "    temp_df['storm_id'] = storm_ids[i]\n",
    "    temp_df['storm_name'] = names[i]\n",
    "    temp_df['basin'] = basins[i]\n",
    "    temp_df['atcf_cyclone_num'] = cyclone_nums[i]\n",
    "    temp_df = temp_df[cols]\n",
    "    data.append(temp_df)\n",
    "\n",
    "pd_atlantic_storms = pd.concat(\n",
    "        data).reset_index(drop=True)[['storm_id', 'basin', 'atcf_cyclone_num', 'storm_name', 'storm_date', 'storm_year', 'storm_time', 'record_identifier',\n",
    "        'storm_status', 'storm_category', 'latitude', 'longitude', 'max_sustained_wind(kt)', 'min_pressure(mbar)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:32:52.396244Z",
     "iopub.status.busy": "2022-10-17T13:32:52.395887Z",
     "iopub.status.idle": "2022-10-17T13:32:59.932459Z",
     "shell.execute_reply": "2022-10-17T13:32:59.931479Z",
     "shell.execute_reply.started": "2022-10-17T13:32:52.396213Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe088f480d6547c3a09ba10e62ee2dcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "atlantic_storms = spark.createDataFrame(pd_atlantic_storms)\n",
    "\n",
    "atlantic_storms = atlantic_storms.withColumn('atl_id', F.row_number().over(Window.partitionBy().orderBy('storm_id'))) \\\n",
    ".select('atl_id', 'storm_id', 'basin', 'atcf_cyclone_num', 'storm_name', 'storm_date', 'storm_year', 'storm_time', 'record_identifier',\n",
    "    'storm_status', 'storm_category', 'latitude', 'longitude', 'max_sustained_wind(kt)', 'min_pressure(mbar)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "atlantic_storms.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "atlantic_storms.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Named Atlantic Storms with US Landfall Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Geopy to map latitude and longitude to location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:34:44.447649Z",
     "iopub.status.busy": "2022-10-17T13:34:44.447277Z",
     "iopub.status.idle": "2022-10-17T13:40:42.789756Z",
     "shell.execute_reply": "2022-10-17T13:40:42.788425Z",
     "shell.execute_reply.started": "2022-10-17T13:34:44.447616Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f365249e4a204e6cb5a761984f50237b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "import geopy.geocoders\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "geopy.geocoders.options.default_ssl_context=ssl.create_default_context(cafile=certifi.where())\n",
    "\n",
    "geolocator=Nominatim(user_agent=\"capstone\", scheme='http', timeout=None)\n",
    "\n",
    "pd_atlantic_storms = atlantic_storms.toPandas()\n",
    "\n",
    "pd_state_data = state_data.toPandas()\n",
    "\n",
    "named_atlantic_storms=pd_atlantic_storms.loc[~pd_atlantic_storms['storm_name'].str.contains(\n",
    "    'UNNAMED')]\n",
    "records=named_atlantic_storms.loc[named_atlantic_storms['record_identifier'] == 'landfall'].reset_index(\n",
    "    drop=True)\n",
    "\n",
    "states_with_codes=dict(\n",
    "    zip(pd_state_data['state'], pd_state_data['state_code']))\n",
    "\n",
    "location_data=[]\n",
    "no_state=0\n",
    "\n",
    "for row in records.itertuples(index=False):\n",
    "    dct={}\n",
    "    location=geolocator.reverse(f'{row.latitude}, {row.longitude}')\n",
    "    if location is not None:\n",
    "        storm_state=location.raw.get('address').get('state')\n",
    "        if storm_state not in states_with_codes.keys():\n",
    "            no_state+=1\n",
    "            continue\n",
    "        else:\n",
    "            dct['atl_id']=row.atl_id\n",
    "            dct['storm_id']=row.storm_id\n",
    "            dct['storm_name']=row.storm_name\n",
    "            dct['storm_year']=row.storm_year\n",
    "            dct['storm_status']=row.storm_status\n",
    "            dct['storm_category']=row.storm_category\n",
    "            dct['state']=storm_state\n",
    "            dct['latitude']=row.latitude\n",
    "            dct['longitude']=row.longitude\n",
    "            temp_df=pd.DataFrame([dct], columns=['storm_id', 'storm_name', 'storm_year',\n",
    "                                 'storm_status', 'storm_category', 'latitude', 'longitude', 'state'])\n",
    "            location_data.append(temp_df)\n",
    "    else:\n",
    "        no_state+=1\n",
    "\n",
    "storms_with_landfall=pd.concat(location_data, sort=False).reset_index().drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:47:59.366503Z",
     "iopub.status.busy": "2022-10-17T13:47:59.366175Z",
     "iopub.status.idle": "2022-10-17T13:47:59.645086Z",
     "shell.execute_reply": "2022-10-17T13:47:59.643846Z",
     "shell.execute_reply.started": "2022-10-17T13:47:59.366474Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c89d54f91c4db9b6f8662ae17abdfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "swl = spark.createDataFrame(storms_with_landfall)\n",
    "\n",
    "swl = swl.withColumn('swl_id', F.row_number().over(Window.partitionBy().orderBy('storm_id', 'storm_name')))\n",
    "\n",
    "named_atlantic_storms_with_us_landfall = swl.join(state_data, 'state', 'inner').select(swl.swl_id, swl.storm_id, swl.storm_name, swl.storm_year,\n",
    "                                 swl.storm_status, swl.storm_category, state_data.state_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "named_atlantic_storms_with_us_landfall.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:48:03.240821Z",
     "iopub.status.busy": "2022-10-17T13:48:03.240372Z",
     "iopub.status.idle": "2022-10-17T13:48:21.044031Z",
     "shell.execute_reply": "2022-10-17T13:48:21.041652Z",
     "shell.execute_reply.started": "2022-10-17T13:48:03.240781Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a09cc531ae0419882bc52db66e95282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+----------+----------+--------------+--------------+----------+\n",
      "|swl_id|storm_id|storm_name|storm_year|  storm_status|storm_category|state_code|\n",
      "+------+--------+----------+----------+--------------+--------------+----------+\n",
      "|     1|AL011953|     ALICE|      1953|tropical storm|tropical storm|        FL|\n",
      "|     2|AL011955|    BRENDA|      1955|tropical storm|tropical storm|        LA|\n",
      "|     3|AL011959|    ARLENE|      1959|tropical storm|tropical storm|        LA|\n",
      "|     4|AL011966|      ALMA|      1966|     hurricane|             1|        FL|\n",
      "|     5|AL011968|      ABBY|      1968|tropical storm|tropical storm|        FL|\n",
      "+------+--------+----------+----------+--------------+--------------+----------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "named_atlantic_storms_with_us_landfall.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Names by Person and Storm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:56:00.238980Z",
     "iopub.status.busy": "2022-10-17T13:56:00.238460Z",
     "iopub.status.idle": "2022-10-17T13:56:00.692544Z",
     "shell.execute_reply": "2022-10-17T13:56:00.691483Z",
     "shell.execute_reply.started": "2022-10-17T13:56:00.238943Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff44343329914310a53c61514f2025c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "storms = named_atlantic_storms_with_us_landfall.alias('storms')\n",
    "names = names_by_state.alias('names')\n",
    "winds_scale = saffir_simpson_hurricane_wind_scale.alias('winds_scale')\n",
    "\n",
    "names_by_person_and_storm = storms.join(names, storms.storm_name == names.birth_name) \\\n",
    ".join(winds_scale, storms.storm_category == winds_scale.category, 'left') \\\n",
    ".select(storms.swl_id, storms.storm_id, names.name_id, storms.storm_name, names.birth_name.alias('baby_name'), storms.storm_year, \n",
    "        names.birth_year.alias('baby_birth_year'), storms.state_code, names.sex.alias('baby_sex'), storms.storm_status, \n",
    "        storms.storm_category, winds_scale.brief_damage_description.alias('storm_damage_description'), names['count'].alias('name_count'))\n",
    "\n",
    "names_by_person_and_storm = names_by_person_and_storm.withColumn('bsn_id', F.row_number().over(Window.partitionBy().orderBy(names_by_person_and_storm.name_count)))\n",
    "\n",
    "names_by_person_and_storm = names_by_person_and_storm.select('bsn_id', 'swl_id', 'storm_id', 'name_id', 'storm_name', 'baby_name', 'storm_year', 'baby_birth_year', \n",
    "                                                             'state_code', 'storm_status', 'storm_category', 'storm_damage_description', 'baby_sex', 'name_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "names_by_person_and_storm.write.mode('overwrite').parquet(os.path.join(bucket, 'transformed_data'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T13:56:03.244614Z",
     "iopub.status.busy": "2022-10-17T13:56:03.244158Z",
     "iopub.status.idle": "2022-10-17T13:57:01.912984Z",
     "shell.execute_reply": "2022-10-17T13:57:01.911646Z",
     "shell.execute_reply.started": "2022-10-17T13:56:03.244577Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d2eebdd51d84cdcacca0ba3d0766dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+--------+-------+----------+---------+----------+---------------+----------+------------+--------------+------------------------+--------+----------+\n",
      "|bsn_id|swl_id|storm_id|name_id|storm_name|baby_name|storm_year|baby_birth_year|state_code|storm_status|storm_category|storm_damage_description|baby_sex|name_count|\n",
      "+------+------+--------+-------+----------+---------+----------+---------------+----------+------------+--------------+------------------------+--------+----------+\n",
      "|     1|    83|AL041992|  71592|    ANDREW|   ANDREW|      1992|           1913|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     2|    83|AL041992|  77047|    ANDREW|   ANDREW|      1992|           1913|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     3|    83|AL041992|  77918|    ANDREW|   ANDREW|      1992|           1913|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     4|    83|AL041992|  86326|    ANDREW|   ANDREW|      1992|           1914|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     5|    83|AL041992| 103684|    ANDREW|   ANDREW|      1992|           1914|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     6|    83|AL041992| 110024|    ANDREW|   ANDREW|      1992|           1914|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     7|    83|AL041992| 128918|    ANDREW|   ANDREW|      1992|           1915|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     8|    83|AL041992| 145221|    ANDREW|   ANDREW|      1992|           1915|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|     9|    83|AL041992| 145360|    ANDREW|   ANDREW|      1992|           1916|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    10|    83|AL041992| 184357|    ANDREW|   ANDREW|      1992|           1917|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    11|    83|AL041992| 201763|    ANDREW|   ANDREW|      1992|           1917|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    12|    83|AL041992| 222145|    ANDREW|   ANDREW|      1992|           1918|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    13|    83|AL041992| 248490|    ANDREW|   ANDREW|      1992|           1918|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    14|    83|AL041992| 331708|    ANDREW|   ANDREW|      1992|           1921|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    15|    83|AL041992| 349962|    ANDREW|   ANDREW|      1992|           1921|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    16|    83|AL041992| 372020|    ANDREW|   ANDREW|      1992|           1922|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    17|    83|AL041992| 476298|    ANDREW|   ANDREW|      1992|           1924|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    18|    83|AL041992| 486145|    ANDREW|   ANDREW|      1992|           1925|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    19|    83|AL041992| 516509|    ANDREW|   ANDREW|      1992|           1926|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "|    20|    83|AL041992| 518709|    ANDREW|   ANDREW|      1992|           1926|        FL|   hurricane|       5-MAJOR|    Catastrophic dama...|       M|        10|\n",
      "+------+------+--------+-------+----------+---------+----------+---------------+----------+------------+--------------+------------------------+--------+----------+\n",
      "only showing top 20 rows"
     ]
    }
   ],
   "source": [
    "names_by_person_and_storm.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T14:07:25.650144Z",
     "iopub.status.busy": "2022-10-17T14:07:25.649817Z",
     "iopub.status.idle": "2022-10-17T14:07:31.628941Z",
     "shell.execute_reply": "2022-10-17T14:07:31.626800Z",
     "shell.execute_reply.started": "2022-10-17T14:07:25.650114Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d22573f833664f75bce0b4313cae04cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_storm_data count before transformations: 55437\n",
      "atlantic_storms count after tranformations: 53501\n",
      "atlantic_storms_header count after tranformations: 1936\n",
      "atlantic_storm_stats count after tranformations: 53501\n",
      "Completeness check passed!"
     ]
    }
   ],
   "source": [
    "print('raw_storm_data count before transformations:', raw_storm_data.count())\n",
    "print('atlantic_storms count after tranformations:', atlantic_storms.count())\n",
    "print('atlantic_storms_header count after tranformations:', atlantic_storms_header.count())\n",
    "print('atlantic_storm_stats count after tranformations:',  atlantic_storm_stats.count())\n",
    "\n",
    "print('\\nStorms data completeness check passed!') if atlantic_storms.count() + atlantic_storms_header.count() == raw_storm_data.count() else print('\\nStorms data completeness \\\n",
    "check failed, some rows may be MIA.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T14:09:04.864017Z",
     "iopub.status.busy": "2022-10-17T14:09:04.863679Z",
     "iopub.status.idle": "2022-10-17T14:10:05.871078Z",
     "shell.execute_reply": "2022-10-17T14:10:05.859925Z",
     "shell.execute_reply.started": "2022-10-17T14:09:04.863988Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3279b562b4e4b2ca39b0652f25f5680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_name_data count before transformations: 6311504\n",
      "names_by_state count after tranformations: 6311504\n",
      "Names data completeness check passed!"
     ]
    }
   ],
   "source": [
    "print('raw_name_data count before transformations:', raw_name_data.count())\n",
    "print('names_by_state count after tranformations:', names_by_state.count())\n",
    "\n",
    "print('\\nNames data completeness check passed!') if raw_name_data.count() == names_by_state.count() else print('\\nNames data completeness check failed, some rows may be MIA.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-17T14:10:16.104419Z",
     "iopub.status.busy": "2022-10-17T14:10:16.104089Z",
     "iopub.status.idle": "2022-10-17T14:10:42.326231Z",
     "shell.execute_reply": "2022-10-17T14:10:42.325077Z",
     "shell.execute_reply.started": "2022-10-17T14:10:16.104390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b3696987d94f2981f82946c5a27427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_state_data count before transformations: 51\n",
      "state_data count after tranformations: 51\n",
      "\n",
      "State data completeness check passed!"
     ]
    }
   ],
   "source": [
    "print('raw_state_data count before transformations:', raw_state_data.count())\n",
    "print('state_data count after tranformations:', state_data.count())\n",
    "\n",
    "print('\\nState data completeness check passed!') if raw_name_data.count() == names_by_state.count() else print('\\nState data completeness check failed, some rows may be MIA.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Atlantic Storm table latitude and longitude quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T14:11:46.859872Z",
     "iopub.status.busy": "2022-10-17T14:11:46.859526Z",
     "iopub.status.idle": "2022-10-17T14:11:47.049873Z",
     "shell.execute_reply": "2022-10-17T14:11:47.048960Z",
     "shell.execute_reply.started": "2022-10-17T14:11:46.859840Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3d691882c7e4747b239d9c04a42bfae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storm_data latitude bool: False\n",
      "storm_data longitude bool: False\n",
      "Latitude and longitude quality check passed!"
     ]
    }
   ],
   "source": [
    "lat_bool = str(atlantic_storms['latitude'])[-1:] == 'N'\n",
    "long_bool = str(atlantic_storms['longitude'])[-1:] == 'W'\n",
    "\n",
    "print('storm_data latitude bool:', lat_bool)\n",
    "print('storm_data longitude bool:', long_bool)\n",
    "print('Latitude and longitude quality check passed!') if (lat_bool is False & long_bool is False) else print('Uh oh, your filtering may have excluded some rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Quality check for storms with names and landfall in the US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "editable": true,
    "execution": {
     "iopub.execute_input": "2022-10-17T14:12:37.424508Z",
     "iopub.status.busy": "2022-10-17T14:12:37.424170Z",
     "iopub.status.idle": "2022-10-17T14:12:55.283149Z",
     "shell.execute_reply": "2022-10-17T14:12:55.276562Z",
     "shell.execute_reply.started": "2022-10-17T14:12:37.424479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b1460d554b43b3a7617d23f0ad309e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of storms with landfall: 663\n",
      "count of storms with landfall in the US: 271\n",
      "count of storms with landfall not in the US: 392\n",
      "Quality check passed!"
     ]
    }
   ],
   "source": [
    "with_state = named_atlantic_storms_with_us_landfall.count() #271\n",
    "total = len(records) # 663\n",
    "print('Storms with landfall:', total)\n",
    "print('Storms with landfall in the US:', with_state)\n",
    "print('Storms with landfall not in the US:', no_state)\n",
    "print('Named Atlantic Storms with US Landfall completeness check passed!') if (with_state + no_state) == total else print('Uh oh, your filtering for Named Atlantic Storms \\\n",
    "with US Landfall may have excluded some rows.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storms_data_dict = pd.read_excel('capstone_data_dictionary.xlsx', 'storm_data')\n",
    "storms_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "names_data_dict = pd.read_excel('capstone_data_dictionary.xlsx', 'names_by_state')\n",
    "names_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "states_data_dict = pd.read_excel('capstone_data_dictionary.xlsx', 'state_data')\n",
    "states_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "wind_scale_data_dict = pd.read_excel('capstone_data_dictionary.xlsx', 'wind_scale')\n",
    "wind_scale_data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "**Rationale for the choice of tools and technologies**<br>\n",
    "Initially, Spark and Hadoop were chosen to carry out the big-data related tasks. A combination because Spark is faster than Hadoop but Hadoop has a distrubited file system that Spark lacks. Udacity focused on using Spark with Hadoop during the lessons; however, Spark proved to be a poor choice for the data given it's size.<br>\n",
    "**How often the data should be updated and why?**<br>\n",
    "The name data and storm data would most likely be updated yearly; the state data and wind_scale data are stagnant for the time being. Updating more frquently than annually would be a gross misuse of resources.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write a description of how you would approach the problem differently under the following scenarios:\n",
    "**The data was increased by 100x.** <br>\n",
    "I would reconsider using ALL Spark with more nodes as I believe it would be more performant handling the data of that size. <br>\n",
    "**The data populates a dashboard that must be updated on a daily basis by 7am every day.** <br>\n",
    "I would use airflow to set up a scheduled run while strongly discouraging updating the data on that schedule. <br>\n",
    "**The database needed to be accessed by 100+ people.** <br>\n",
    "As the data is in S3 I don't forsee this being an issue. Per Amazon's documentation, S3 can handle up to 5,500 GET requests per seconds and allows concurrent access. Using Spark to perform real time queries would run great in this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storms_header_dim = spark.read.parquet(os.path.join(bucket, '*', '*', '*', 'storm_headers.parquet'))\n",
    "atlantic_storms_header_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storm_stats_dim = spark.read.parquet(os.path.join(bucket, '*', '*', '*', 'storm_stats.parquet'))\n",
    "atlantic_storm_stats_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlantic_storms_dim = spark.read.parquet(os.path.join(bucket, '*', '*', '*', 'atlantic_storms.parquet'))\n",
    "atlantic_storms_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_by_state_dim = spark.read.parquet(os.path.join(bucket, '*', '*', 'names_by_state.parquet'))\n",
    "names_by_state_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_scale_dim = spark.read.parquet(os.path.join(bucket, '*', '*', 'wind_scale.parquet'))\n",
    "wind_scale_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dim = spark.read.parquet(os.path.join(bucket, '*', '*', 'state_data.parquet'))\n",
    "state_dim.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "named_atlantic_storms_fact = spark.read.parquet(os.path.join(bucket, '*', '*', 'storms_with_us_landfall.parquet'))\n",
    "named_atlantic_storms_fact.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_by_person_and_storm_fact = spark.read.parquet(os.path.join(bucket, '*', '*', 'names_by_person_and_storm_fact.parquet'))\n",
    "names_by_person_and_storm_fact.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
